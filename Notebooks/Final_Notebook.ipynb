{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data** **cleaning**"
      ],
      "metadata": {
        "id": "hPbN8tXCN57E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODg2W9KNL3Oh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "\n",
        "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "file_path = os.path.join(CURRENT_DIR,\"raw\" , \"ObesityDataSet.csv\")\n",
        "\n",
        "# Charger le dataset\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier le chargement des données\n",
        "print(\"Aperçu des données :\")\n",
        "print(df.head())\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "print(\"\n",
        "Valeurs manquantes par colonne :\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Vérifier si certaines valeurs sont codées différemment comme manquantes\n",
        "print(\"\n",
        "Valeurs potentiellement manquantes sous d'autres formes ('?', 'None', '') :\")\n",
        "print(df.isin(['?', 'None', '']).sum())\n",
        "\n",
        "# Obtenir un résumé des données\n",
        "print(\"\n",
        "Résumé des colonnes et valeurs non nulles :\")\n",
        "print(df.info())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "# Affichage des outliers avec un boxplot\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns\n",
        "df_numerical = df[numerical_cols]\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.boxplot(data=df_numerical)\n",
        "plt.title(\"Boxplots des variables numériques\", fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Suppression des outliers\n",
        "lower_weight, upper_weight = 40, 105\n",
        "lower_age, upper_age = 10, 26\n",
        "\n",
        "df_filtered = df[\n",
        "    (df['Weight'] >= lower_weight) & (df['Weight'] <= upper_weight) &\n",
        "    (df['Age'] >= lower_age) & (df['Age'] <= upper_age)\n",
        "]\n",
        "\n",
        "# Sauvegarde des données nettoyées\n",
        "processed_path = os.path.join(CURRENT_DIR, \"data\", \"processed\", \"dataset.csv\")\n",
        "\n",
        "# Créer le dossier si inexistant\n",
        "os.makedirs(os.path.dirname(processed_path), exist_ok=True)\n",
        "df_filtered.to_csv(processed_path, index=False)\n",
        "print(f'✅ Données nettoyées sauvegardées dans : {processed_path}')\n",
        "\n",
        "# Encodage de la colonne cible\n",
        "le = LabelEncoder()\n",
        "df_filtered['NObeyesdad'] = le.fit_transform(df_filtered['NObeyesdad'])\n",
        "\n",
        "# Sauvegarde de l'encodeur\n",
        "encoder_path = os.path.join(CURRENT_DIR, \"data\", \"processed\", \"label_encoder.pkl\")\n",
        "with open(encoder_path, \"wb\") as file:\n",
        "    pickle.dump(le, file)\n",
        "\n",
        "print(f'✅ Label Encoder sauvegardé dans : {encoder_path}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class Distriburtion & Correlation**"
      ],
      "metadata": {
        "id": "Dj6lCCeeKCsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Class distribution\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "file_path = os.path.join(CURRENT_DIR, \"dataset.csv\")\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Check class distribution and display percentages\n",
        "class_counts = df[\"NObeyesdad\"].value_counts(normalize=True) * 100  # Get percentages\n",
        "print(\"Class Distribution:\\n\", class_counts)\n",
        "\n",
        "# Plot Class Distribution with percentages displayed\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values, palette=\"viridis\")\n",
        "for i, v in enumerate(class_counts.values):\n",
        "    plt.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')  # Adding percentages on top of bars\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Obesity Level\")\n",
        "plt.ylabel(\"Percentage of Samples\")\n",
        "plt.title(\"Class Distribution of Obesity Levels\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Box plot of all numerical columns\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot of Numerical Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "########### Boxplot for Age vs. Obesity Level ##########\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=df[\"NObeyesdad\"], y=df[\"Age\"], palette=\"coolwarm\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Age Distribution Across Obesity Levels\")\n",
        "plt.show()\n",
        "\n",
        "########### Boxplot for Weight vs. Obesity Level ##########\n",
        "sns.boxplot(x=df[\"NObeyesdad\"], y=df[\"Weight\"], palette=\"coolwarm\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Weight Distribution Across Obesity Levels\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "########### Boxplot for Weight vs. Obesity Level ##########\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=df[\"NObeyesdad\"], y=df[\"Weight\"], palette=\"coolwarm\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Weight Distribution Across Obesity Levels\")\n",
        "plt.show()\n",
        "\n",
        "########### Boxplot for Physical Activity Frequency (FAF) vs. Obesity Level ##########\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=df[\"NObeyesdad\"], y=df[\"FAF\"], palette=\"coolwarm\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Physical Activity (FAF) Across Obesity Levels\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "########### Print Class Distribution ##########\n",
        "class_counts = df[\"NObeyesdad\"].value_counts(normalize=True) * 100\n",
        "print(\"Class Distribution:\\n\", class_counts)\n",
        "\n",
        "\n",
        "#understanding correlation and computing correlation matrix\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Charger les données\n",
        "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "file_path = os.path.join(CURRENT_DIR, \"dataset.csv\")\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert all categorical columns to numeric\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    df[col] = df[col].astype('category').cat.codes\n",
        "\n",
        "# Convert categorical target variable to numeric for correlation analysis\n",
        "df[\"Obesity_Level_Num\"] = df[\"NObeyesdad\"].astype(\"category\").cat.codes\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Print class distribution as percentages\n",
        "print(df['NObeyesdad'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Convert categorical features to numeric (using one-hot encoding)\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Compute correlation matrix of the encoded data\n",
        "correlation_matrix = df_encoded.corr()\n",
        "\n",
        "# Plot heatmap of the correlation matrix after encoding\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Matrix \")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h4o-W1fWLHOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model TRaining**"
      ],
      "metadata": {
        "id": "dyODh4e4KO3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import gc\n",
        "import psutil\n",
        "import os\n",
        "import pickle\n",
        "import shap\n",
        "\n",
        "\n",
        "# === data loading ===\n",
        "# Get the absolute path of the current script (inside views/)\n",
        "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "# Move up one level to reach the project root\n",
        "BASE_DIR = os.path.abspath(os.path.join(CURRENT_DIR, \"..\"))\n",
        "\n",
        "# Construct paths relative to the project root\n",
        "DATA_PATH = os.path.join(BASE_DIR, \"data\",\"processed\" , \"dataset.csv\")\n",
        "df= pd.read_csv(DATA_PATH)\n",
        "\n",
        "# === memory reducing ===\n",
        "def optimize_dataframe(df):\n",
        "    for col in df.select_dtypes(include=['int64']).columns:\n",
        "        df[col] = df[col].astype('int32')\n",
        "    for col in df.select_dtypes(include=['float64']).columns:\n",
        "        df[col] = df[col].astype('float32')\n",
        "    return df\n",
        "\n",
        "df = optimize_dataframe(df)\n",
        "categorical_columns = [\"Gender\", \"family_history_with_overweight\", \"NObeyesdad\",\"FAVC\",\"SMOKE\",\"CAEC\",\"SCC\",\"CALC\",\"MTRANS\",]\n",
        "\n",
        "# ==== spliting data ====\n",
        "# Apply Label Encoding\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save encoders if you need to inverse transform later\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = df.drop(\"NObeyesdad\", axis=1)  # Features\n",
        "y = df[\"NObeyesdad\"]  # Target (Obesity Level)\n",
        "\n",
        "\n",
        "# Split into 80% Training and 20% Testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Size:\", X_train.shape)\n",
        "print(\"Testing Set Size:\", X_test.shape)\n",
        "\n",
        "\n",
        "# ==== FLAGS FOR SAMPLING METHODS ====\n",
        "USE_SMOTE = True           # Enable/Disable Oversampling\n",
        "USE_UNDERSAMPLING = True  # Enable/Disable Undersampling\n",
        "USE_CLASS_WEIGHTS = False  # Set this to True to use class weighting\n",
        "\n",
        "\n",
        "# Apply Oversampling (SMOTE)\n",
        "if USE_SMOTE:\n",
        "    smote = SMOTE(sampling_strategy=\"auto\", random_state=42)  # 60% oversampling\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "    print(\"Applied SMOTE Oversampling. New Training Set Size:\", X_train.shape)\n",
        "\n",
        "# Apply Undersampling (RandomUnderSampler)\n",
        "if USE_UNDERSAMPLING:\n",
        "    undersample = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)  # 80% of majority class\n",
        "    X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
        "    print(\"Applied Random UnderSampling. New Training Set Size:\", X_train.shape)\n",
        "\n",
        "# Compute Class Weights (If Selected)\n",
        "class_weight_dict = None\n",
        "if USE_CLASS_WEIGHTS:\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\",\n",
        "                                         classes=np.unique(y_train), y=y_train)\n",
        "    class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
        "    print(\"Applied Class Weights:\", class_weight_dict)\n",
        "\n",
        "\n",
        "# ===== training =====\n",
        "\n",
        "# Initialize Model with Selected Class Weights\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42,\n",
        "                               class_weight=class_weight_dict if USE_CLASS_WEIGHTS else \"balanced\")\n",
        "# Train Model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Save the trained model to a file\n",
        "with open(\"obesity_model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "\n",
        "# Train SHAP explainer after training your model\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)  # Ensure X_test matches training format\n",
        "\n",
        "\n",
        "# Save SHAP explainer to a file\n",
        "with open(\"shap_explainer.pkl\", \"wb\") as file:\n",
        "      pickle.dump(explainer, file)\n",
        "\n",
        "print(\"SHAP explainer saved successfully as shap_explainer.pkl!\")\n",
        "\n",
        "\n",
        "# === Memmory Optimization ===\n",
        "\n",
        "def get_memory_usage():\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / (1024 * 1024)  # Convertir en Mo\n",
        "\n",
        "memory_used = get_memory_usage()\n",
        "print(f\" Memory use after execution : {memory_used:.2f} Mo\")\n",
        "variables_a_supprimer = [var for var in globals().keys() if var not in [\"get_memory_usage\", \"gc\", \"psutil\", \"pickle\", \"shap\", \"__name__\", \"__file__\", \"__builtins__\"]]\n",
        "\n",
        "\n",
        "for var in variables_a_supprimer:\n",
        "    del globals()[var]\n",
        "\n",
        "gc.collect()\n",
        "print(\" Memory freed !\")\n"
      ],
      "metadata": {
        "id": "G4DypFLLNZPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model** **Evaluation**"
      ],
      "metadata": {
        "id": "h46pOu2JNkBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import psutil\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# === DATA & MODEL LOADING ===\n",
        "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "BASE_DIR = os.path.abspath(os.path.join(CURRENT_DIR, \"..\"))\n",
        "\n",
        "# Construct paths\n",
        "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"processed\", \"dataset.csv\")\n",
        "MODEL_PATH = os.path.join(BASE_DIR, \"models\", \"obesity_model.pkl\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Load trained model\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"Model file not found: {MODEL_PATH}\")\n",
        "\n",
        "print(f\"Loading model from: {MODEL_PATH}\")\n",
        "model = joblib.load(MODEL_PATH)\n",
        "\n",
        "# === DATA PREPARATION ===\n",
        "categorical_columns = [\"Gender\", \"family_history_with_overweight\", \"FAVC\", \"SMOKE\",\n",
        "                       \"CAEC\", \"SCC\", \"CALC\", \"MTRANS\", \"NObeyesdad\"]\n",
        "\n",
        "# Apply Label Encoding\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save encoders for inverse transform if needed\n",
        "\n",
        "# Split features & target variable\n",
        "X = df.drop(\"NObeyesdad\", axis=1)\n",
        "y = df[\"NObeyesdad\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# === PREDICTION ===\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# === MODEL EVALUATION ===\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\" Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# === CONFUSION MATRIX ===\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=set(y_test), yticklabels=set(y_test))\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# === ROC-AUC SCORE ===\n",
        "y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))\n",
        "roc_auc = roc_auc_score(y_test_binarized, model.predict_proba(X_test), multi_class=\"ovr\")\n",
        "print(f\" ROC-AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "# === MEMORY OPTIMIZATION ===\n",
        "def get_memory_usage():\n",
        "    process = psutil.Process()\n",
        "    return process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
        "\n",
        "memory_used = get_memory_usage()\n",
        "print(f\" Memory usage after execution: {memory_used:.2f} MB\")\n",
        "\n",
        "# Clean up memory\n",
        "variables_to_keep = {\"get_memory_usage\", \"gc\", \"psutil\", \"__name__\", \"__file__\", \"__builtins__\"}\n",
        "for var in list(globals().keys()):\n",
        "    if var not in variables_to_keep:\n",
        "        del globals()[var]\n",
        "\n",
        "gc.collect()\n",
        "print(\" Memory freed!\")\n"
      ],
      "metadata": {
        "id": "_TEr9yO9NoQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shap** **Explainer**"
      ],
      "metadata": {
        "id": "qz0FAxDoNtl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import shap\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# === DATA AND MODEL LOADING ===\n",
        "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "BASE_DIR = os.path.abspath(os.path.join(CURRENT_DIR, \"..\"))\n",
        "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"processed\", \"dataset.csv\")\n",
        "MODEL_PATH = os.path.join(BASE_DIR, \"models\", \"obesity_model.pkl\")\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"Model file not found: {MODEL_PATH}\")\n",
        "\n",
        "print(f\"🔹 Loading model from: {MODEL_PATH}\")\n",
        "model = joblib.load(MODEL_PATH)\n",
        "\n",
        "# === DATA PREPARATION ===\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "categorical_columns = [\"Gender\", \"family_history_with_overweight\", \"FAVC\", \"SMOKE\",\n",
        "                       \"CAEC\", \"SCC\", \"CALC\", \"MTRANS\"]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save encoders for inverse transform if needed\n",
        "\n",
        "X = df.drop(\"NObeyesdad\", axis=1)\n",
        "y = df[\"NObeyesdad\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# === SHAP EXPLAINER ===\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# === Ploting Shap ===\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "print(\" SHAP analysis completed successfully!\")\n"
      ],
      "metadata": {
        "id": "vbQuVIS-Nwx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***tests***\n"
      ],
      "metadata": {
        "id": "AI2-Ql3Je06D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Ensure we can import modules from the main project directory\n",
        "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n",
        "\n",
        "# Import the prediction function from the obesity controller\n",
        "from controllers.obesity_controller import predict_obesity\n",
        "\n",
        "# Get the absolute path of the current script (inside views/)\n",
        "CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "\n",
        "# Move up one level to reach the project root\n",
        "BASE_DIR = os.path.abspath(os.path.join(CURRENT_DIR, \"..\"))\n",
        "\n",
        "# Define paths for data and model\n",
        "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"processed\", \"dataset.csv\")\n",
        "MODEL_PATH = os.path.join(BASE_DIR, \"models\", \"obesity_model.pkl\")\n",
        "\n",
        "# Ensure consistent feature selection\n",
        "EXPECTED_FEATURES = [\n",
        "    \"Gender\", \"Age\", \"Height\", \"Weight\", \"family_history_with_overweight\",\n",
        "    \"FAVC\", \"FCVC\", \"NCP\", \"CAEC\", \"SMOKE\", \"CH2O\", \"SCC\", \"FAF\", \"TUE\", \"CALC\", \"MTRANS\"\n",
        "]\n",
        "\n",
        "# Load the trained model\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"⚠ Model file not found at {MODEL_PATH}\")\n",
        "\n",
        "with open(MODEL_PATH, \"rb\") as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# Test functions\n",
        "\n",
        "def test_prediction():\n",
        "    \"\"\"Test a prediction with valid values\"\"\"\n",
        "    features = {\n",
        "        \"Age\": 30, \"Height\": 1.80, \"Weight\": 80,\n",
        "        \"Activity\": 2, \"Food_Intake\": 2, \"Vegetables\": 3, \"Water_Intake\": 2, \"Smoking\": 0\n",
        "    }\n",
        "    prediction = predict_obesity(features)\n",
        "    valid_classes = [\"Poids Insuffisant\", \"Poids Normal\", \"Surpoids Niveau I\",\n",
        "                     \"Surpoids Niveau II\", \"Obésité Type I\", \"Obésité Type II\", \"Obésité Type III\"]\n",
        "\n",
        "    assert prediction in valid_classes, f\"⚠ Invalid prediction: {prediction}\"\n",
        "\n",
        "def test_dataset_loading():\n",
        "    \"\"\"Test loading the dataset\"\"\"\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    assert not df.empty, \"⚠ The dataset is empty\"\n",
        "\n",
        "def test_data_types():\n",
        "    \"\"\"Test that numerical columns are in the correct format\"\"\"\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    numerical_columns = [\"Age\", \"Height\", \"Weight\"]\n",
        "\n",
        "    for col in numerical_columns:\n",
        "        assert df[col].dtype in [\"int64\", \"float64\"], f\"⚠ Wrong data type for {col}\"\n",
        "\n",
        "def test_model_loading():\n",
        "    \"\"\"Test if the model loads correctly\"\"\"\n",
        "    assert model is not None, \"⚠ Model failed to load!\"\n",
        "\n",
        "def test_model_prediction():\n",
        "    \"\"\"Test model prediction with a sample input\"\"\"\n",
        "    sample_input = pd.DataFrame([{\n",
        "        \"Gender\": 1, \"Age\": 30, \"Height\": 170, \"Weight\": 75,\n",
        "        \"family_history_with_overweight\": 1, \"FAVC\": 1, \"FCVC\": 2.5, \"NCP\": 3,\n",
        "        \"CAEC\": 2, \"SMOKE\": 0, \"CH2O\": 2, \"SCC\": 1, \"FAF\": 1.5, \"TUE\": 1.5, \"CALC\": 1, \"MTRANS\": 2\n",
        "    }])\n",
        "\n",
        "    # Ensure only expected features are used\n",
        "    sample_input = sample_input[EXPECTED_FEATURES]\n",
        "\n",
        "    # Check that the input matches model expectations\n",
        "    assert sample_input.shape[1] == len(EXPECTED_FEATURES), f\"⚠ Expected {len(EXPECTED_FEATURES)} features, got {sample_input.shape[1]}\"\n",
        "\n",
        "    # Run prediction\n",
        "    prediction = model.predict(sample_input)\n",
        "\n",
        "    # Check that output is a valid class\n",
        "    valid_classes = [0, 1, 2, 3, 4, 5, 6]  # Adjust based on your label encoding\n",
        "    assert prediction[0] in valid_classes, f\"⚠ Invalid prediction output: {prediction[0]}\"\n",
        "\n",
        "# Run all tests\n",
        "def run_tests():\n",
        "    \"\"\"Run all test functions\"\"\"\n",
        "    test_prediction()\n",
        "    test_dataset_loading()\n",
        "    test_data_types()\n",
        "    test_model_loading()\n",
        "    test_model_prediction()\n",
        "    print(\"✅ All tests passed successfully!\")\n",
        "\n",
        "# Execute the tests\n",
        "if __name__ == \"__main__\":\n",
        "    run_tests()"
      ],
      "metadata": {
        "id": "94RqXNyTfCst"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}